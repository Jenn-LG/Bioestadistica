# 2. Quitar columnas originales y unir dummies
df_temp_ready = pd.concat([df_temp_ready.drop(columns=categoricas), temp_dummies], axis=1)
# Para clorofila
# 1. Crear dummies aparte
cloro_dummies = pd.get_dummies(df_cloro_ready[categoricas], prefix=categoricas, drop_first=False).astype(int)
# 2. Quitar columnas originales y unir dummies
df_cloro_ready = pd.concat([df_cloro_ready.drop(columns=categoricas), cloro_dummies], axis=1)
# Estaciones de temperatura y clorofila
temp_estaciones = [col for col in df_temp_ready.columns if 'Est' in col]
cloro_estaciones = [col for col in df_cloro_ready.columns if 'Est' in col]
df_temp_ready['temp_promedio'] = df_temp_ready[temp_estaciones].mean(axis=1)
df_temp_ready['evento'] = df_temp_cut['EVENTO INTERANUAL']
df_cloro_ready['cloro_promedio'] = df_cloro_ready[cloro_estaciones].mean(axis=1)
df_cloro_ready['evento'] = df_cloro_cut['EVENTO INTERANUAL']  # traer original
# Promedio total por estación (temperatura)
temp_mean = df_temp_ready[temp_estaciones].mean()
temp_std = df_temp_ready[temp_estaciones].std()
# Promedio total por estación (clorofila)
cloro_mean = df_cloro_ready[cloro_estaciones].mean()
cloro_std = df_cloro_ready[cloro_estaciones].std()
# Combinar en un solo DataFrame resumen
resumen_estaciones = pd.DataFrame({
'temp_mean': temp_mean,
'temp_std': temp_std,
'cloro_mean': cloro_mean,
'cloro_std': cloro_std
})
print("Resumen de métricas por estación:")
print(resumen_estaciones)
#| echo: false
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
# Seleccionar solo columnas numéricas
X_numeric = resumen_estaciones.select_dtypes(include='number')
# Escalar los datos
scaler = StandardScaler()
X_clustering = scaler.fit_transform(X_numeric)
# Método del codo
inertias = []
K = range(1, 11)
for k in K:
kmeans = KMeans(n_clusters=k, random_state=42)
kmeans.fit(X_clustering)
inertias.append(kmeans.inertia_)
# Gráfico del codo
plt.figure(figsize=(8, 5))
plt.plot(K, inertias, marker='o')
plt.xlabel('Número de clusters (k)')
plt.ylabel('Inercia')
plt.title('Método del codo para encontrar el número óptimo de clusters')
plt.grid(True)
plt.show()
#| echo: false
# PASO 2: Clustering con K-means
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
# Definir número de clusters (ajustable)
n_clusters = 3
# Seleccionar solo las métricas para clustering
X_clustering = resumen_estaciones.values
# Ajustar modelo K-means
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
resumen_estaciones['cluster'] = kmeans.fit_predict(X_clustering)
print("Clusters asignados por estación:")
print(resumen_estaciones[['cluster']])
# Visualización rápida
plt.figure(figsize=(8, 6))
plt.scatter(resumen_estaciones['temp_mean'], resumen_estaciones['cloro_mean'],
c=resumen_estaciones['cluster'], cmap='viridis', s=100)
plt.xlabel('Temperatura media')
plt.ylabel('Clorofila media')
plt.title('Clusters de estaciones')
plt.colorbar(label='Cluster')
plt.show()
#| echo: false
import pandas as pd
ruta_temp = 'data/Base de datos TSM consultoria estadística.xlsx'
df_temp = pd.read_excel(ruta_temp)
# Cargar archivo de clorofila
ruta_cloro = 'data/Base de datos Chla consultoria estadística.xlsx'
df_cloro = pd.read_excel(ruta_cloro)
df_temp.columns = df_temp.columns.str.strip()
df_cloro.columns = df_cloro.columns.str.strip()
df_temp['EVENTO INTERANUAL'] = df_temp['EVENTO INTERANUAL'].replace({'Neutro': 'Normal'})
# Recortar ambos al mismo rango: 1997-09-01 a 2018-10-01
start_date = pd.Timestamp('1997-09-01')
end_date = pd.Timestamp('2018-10-01')
df_temp_cut = df_temp[(df_temp['FECHA'] >= start_date) & (df_temp['FECHA'] <= end_date)].reset_index(drop=True)
df_cloro_cut = df_cloro[(df_cloro['FECHA'] >= start_date) & (df_cloro['FECHA'] <= end_date)].reset_index(drop=True)
df_temp_ready = df_temp_cut.copy()
df_cloro_ready = df_cloro_cut.copy()
# Variables categóricas que queremos convertir a dummies
categoricas = ['EVENTO INTERANUAL', 'MES', 'ESTACIÓN DEL AÑO']
# Para temperatura
# 1. Crear dummies aparte
temp_dummies = pd.get_dummies(df_temp_ready[categoricas], prefix=categoricas, drop_first=False).astype(int)
# 2. Quitar columnas originales y unir dummies
df_temp_ready = pd.concat([df_temp_ready.drop(columns=categoricas), temp_dummies], axis=1)
# Para clorofila
# 1. Crear dummies aparte
cloro_dummies = pd.get_dummies(df_cloro_ready[categoricas], prefix=categoricas, drop_first=False).astype(int)
# 2. Quitar columnas originales y unir dummies
df_cloro_ready = pd.concat([df_cloro_ready.drop(columns=categoricas), cloro_dummies], axis=1)
# Estaciones de temperatura y clorofila
temp_estaciones = [col for col in df_temp_ready.columns if 'Est' in col]
cloro_estaciones = [col for col in df_cloro_ready.columns if 'Est' in col]
df_temp_ready['temp_promedio'] = df_temp_ready[temp_estaciones].mean(axis=1)
df_temp_ready['evento'] = df_temp_cut['EVENTO INTERANUAL']
df_cloro_ready['cloro_promedio'] = df_cloro_ready[cloro_estaciones].mean(axis=1)
df_cloro_ready['evento'] = df_cloro_cut['EVENTO INTERANUAL']  # traer original
# Promedio total por estación (temperatura)
temp_mean = df_temp_ready[temp_estaciones].mean()
temp_std = df_temp_ready[temp_estaciones].std()
# Promedio total por estación (clorofila)
cloro_mean = df_cloro_ready[cloro_estaciones].mean()
cloro_std = df_cloro_ready[cloro_estaciones].std()
# Combinar en un solo DataFrame resumen
resumen_estaciones = pd.DataFrame({
'temp_mean': temp_mean,
'temp_std': temp_std,
'cloro_mean': cloro_mean,
'cloro_std': cloro_std
})
print("Resumen de métricas por estación:")
print(resumen_estaciones)
#| echo: false
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
# Seleccionar solo columnas numéricas
X_numeric = resumen_estaciones.select_dtypes(include='number')
# Escalar los datos
scaler = StandardScaler()
X_clustering = scaler.fit_transform(X_numeric)
# Método del codo
inertias = []
K = range(1, 11)
for k in K:
kmeans = KMeans(n_clusters=k, random_state=42)
kmeans.fit(X_clustering)
inertias.append(kmeans.inertia_)
# Gráfico del codo
plt.figure(figsize=(8, 5))
plt.plot(K, inertias, marker='o')
plt.xlabel('Número de clusters (k)')
plt.ylabel('Inercia')
plt.title('Método del codo para encontrar el número óptimo de clusters')
plt.grid(True)
plt.show()
#| echo: false
# PASO 2: Clustering con K-means
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
# Definir número de clusters (ajustable)
n_clusters = 3
# Seleccionar solo las métricas para clustering
X_clustering = resumen_estaciones.values
# Ajustar modelo K-means
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
resumen_estaciones['cluster'] = kmeans.fit_predict(X_clustering)
print("Clusters asignados por estación:")
print(resumen_estaciones[['cluster']])
# Visualización rápida
plt.figure(figsize=(8, 6))
plt.scatter(resumen_estaciones['temp_mean'], resumen_estaciones['cloro_mean'],
c=resumen_estaciones['cluster'], cmap='viridis', s=100)
plt.xlabel('Temperatura media')
plt.ylabel('Clorofila media')
plt.title('Clusters de estaciones')
plt.colorbar(label='Cluster')
plt.show()
#| echo: false
coordenadas = 'data/Coordenadas zona costera occidental GC.csv'
df_coords = pd.read_csv(coordenadas, header=None)
# Eliminar columna con NaNs (columna 1)
df_coords_clean = df_coords.drop(columns=[1])
# Renombrar columnas para claridad
df_coords_clean.columns = ['lon', 'lat']
# Permutar columnas: dejar como lat, lon
df_coords_clean = df_coords_clean[['lat', 'lon']]
df_coords_clean['Estación'] = [f'Est {i+1}°' for i in range(len(df_coords_clean))]
df_coords_clean.columns = df_coords_clean.columns.str.strip()
#| echo: false
# Primero, recuperamos el evento original como columna categórica
df_temp_ready['evento'] = df_temp_cut['EVENTO INTERANUAL']
df_cloro_ready['evento'] = df_cloro_cut['EVENTO INTERANUAL']
# Crear tabla de promedio por estación y evento (para temperatura)
temp_evento_mean = df_temp_ready.groupby('evento')[temp_estaciones].mean().T.reset_index().melt(
id_vars='index', var_name='Evento', value_name='Temp promedio'
).rename(columns={'index': 'Estación'})
# Crear tabla de promedio por estación y evento (para clorofila)
cloro_evento_mean = df_cloro_ready.groupby('evento')[cloro_estaciones].mean().T.reset_index().melt(
id_vars='index', var_name='Evento', value_name='Cloro promedio'
).rename(columns={'index': 'Estación'})
# Unir ambas
respuestas_evento = pd.merge(temp_evento_mean, cloro_evento_mean, on=['Estación', 'Evento'])
# Ordenar por número de estación
respuestas_evento['n_est'] = respuestas_evento['Estación'].str.extract(r'(\d+)').astype(int)
respuestas_evento = respuestas_evento.sort_values('n_est')
# Pivotear a formato ancho por estación
pivot_temp = respuestas_evento.pivot(index='Estación', columns='Evento', values='Temp promedio')
pivot_cloro = respuestas_evento.pivot(index='Estación', columns='Evento', values='Cloro promedio')
# Renombrar columnas para claridad
pivot_temp.columns = [f'Temp_{col}' for col in pivot_temp.columns]
pivot_cloro.columns = [f'Cloro_{col}' for col in pivot_cloro.columns]
# Unir todo
tabla_kmeans = pd.concat([pivot_temp, pivot_cloro], axis=1)
# Ver resultado ordenado
tabla_kmeans = tabla_kmeans.reset_index()
tabla_kmeans['n_est'] = tabla_kmeans['Estación'].str.extract(r'(\d+)').astype(int)
tabla_kmeans = tabla_kmeans.sort_values('n_est').drop(columns='n_est').set_index('Estación')
tabla_kmeans.head(18)
#| echo: false
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
# Escalar los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(tabla_kmeans)
# Método del codo
inertias = []
K = range(1, 11)
for k in K:
kmeans = KMeans(n_clusters=k, random_state=42)
kmeans.fit(X_scaled)
inertias.append(kmeans.inertia_)
# Graficar el codo
plt.figure(figsize=(8, 5))
plt.plot(K, inertias, marker='o')
plt.xlabel('Número de clusters (k)')
plt.ylabel('Inercia')
plt.title('Método del codo para encontrar el número óptimo de clusters')
plt.grid(True)
plt.show()
#| echo: false
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
# Escalar los datos
X = StandardScaler().fit_transform(tabla_kmeans.drop(columns='cluster', errors='ignore'))
# KMeans con 3 clusters
kmeans = KMeans(n_clusters=3, random_state=42)
tabla_kmeans['cluster'] = kmeans.fit_predict(X)
# Crear figura con 3 subplots
fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)
# Títulos de cada evento
eventos = ['Niña', 'Niño', 'Normal']
for i, evento in enumerate(eventos):
axs[i].scatter(tabla_kmeans[f'Temp_{evento}'], tabla_kmeans[f'Cloro_{evento}'],
c=tabla_kmeans['cluster'], cmap='viridis', s=100, edgecolor='k')
axs[i].set_xlabel(f'Temperatura promedio ({evento})')
axs[i].set_title(f'Evento: {evento}')
axs[i].grid(True, linestyle='--', alpha=0.3)
axs[0].set_ylabel('Clorofila promedio')
fig.suptitle('Clusters ENSO por evento (KMeans, k=3)', fontsize=16)
plt.tight_layout()
plt.subplots_adjust(top=0.85)
plt.show()
#| echo: false
df_temp_long = df_temp_ready.melt(
id_vars=[col for col in df_temp_ready.columns if col not in tabla_kmeans_geo['Estación'].tolist()],
value_vars=tabla_kmeans_geo['Estación'].tolist(),
var_name='Estación',
value_name='TSM'
)
df_cloro_long = df_cloro_ready.melt(
id_vars=[col for col in df_cloro_ready.columns if col not in tabla_kmeans_geo['Estación'].tolist()],
value_vars=tabla_kmeans_geo['Estación'].tolist(),
var_name='Estación',
value_name='Chl_a'
)
# Crear diccionario Estación
cluster_dict = tabla_kmeans_geo.set_index('Estación')['cluster'].to_dict()
# Mapear al DataFrame largo
df_temp_long['cluster'] = df_temp_long['Estación'].map(cluster_dict)
df_cloro_long['cluster'] = df_cloro_long['Estación'].map(cluster_dict)
import statsmodels.api as sm
for i in sorted(df_temp_long['cluster'].unique()):
print(f"\n=== Cluster {i} ===")
cluster_data = df_temp_long[df_temp_long['cluster'] == i]
for est in cluster_data['Estación'].unique():
subset = cluster_data[cluster_data['Estación'] == est]
X = subset[[col for col in subset.columns if col.startswith('AÑO') or
col.startswith('EVENTO INTERANUAL_') or
col.startswith('MES_') or
col.startswith('ESTACIÓN DEL AÑO_')]]
X = sm.add_constant(X)
y = subset['TSM']
modelo = sm.OLS(y, X).fit()
print(f"\n--- Estación: {est} ---")
print(modelo.summary())
#| echo: false
import pandas as pd
ruta_temp = 'data/Base de datos TSM consultoria estadística.xlsx'
df_temp = pd.read_excel(ruta_temp)
# Cargar archivo de clorofila
ruta_cloro = 'data/Base de datos Chla consultoria estadística.xlsx'
df_cloro = pd.read_excel(ruta_cloro)
df_temp.columns = df_temp.columns.str.strip()
df_cloro.columns = df_cloro.columns.str.strip()
df_temp['EVENTO INTERANUAL'] = df_temp['EVENTO INTERANUAL'].replace({'Neutro': 'Normal'})
# Recortar ambos al mismo rango: 1997-09-01 a 2018-10-01
start_date = pd.Timestamp('1997-09-01')
end_date = pd.Timestamp('2018-10-01')
df_temp_cut = df_temp[(df_temp['FECHA'] >= start_date) & (df_temp['FECHA'] <= end_date)].reset_index(drop=True)
df_cloro_cut = df_cloro[(df_cloro['FECHA'] >= start_date) & (df_cloro['FECHA'] <= end_date)].reset_index(drop=True)
df_temp_ready = df_temp_cut.copy()
df_cloro_ready = df_cloro_cut.copy()
# Variables categóricas que queremos convertir a dummies
categoricas = ['EVENTO INTERANUAL', 'MES', 'ESTACIÓN DEL AÑO']
# Para temperatura
# 1. Crear dummies aparte
temp_dummies = pd.get_dummies(df_temp_ready[categoricas], prefix=categoricas, drop_first=False).astype(int)
# 2. Quitar columnas originales y unir dummies
df_temp_ready = pd.concat([df_temp_ready.drop(columns=categoricas), temp_dummies], axis=1)
# Para clorofila
# 1. Crear dummies aparte
cloro_dummies = pd.get_dummies(df_cloro_ready[categoricas], prefix=categoricas, drop_first=False).astype(int)
# 2. Quitar columnas originales y unir dummies
df_cloro_ready = pd.concat([df_cloro_ready.drop(columns=categoricas), cloro_dummies], axis=1)
# Estaciones de temperatura y clorofila
temp_estaciones = [col for col in df_temp_ready.columns if 'Est' in col]
cloro_estaciones = [col for col in df_cloro_ready.columns if 'Est' in col]
df_temp_ready['temp_promedio'] = df_temp_ready[temp_estaciones].mean(axis=1)
df_temp_ready['evento'] = df_temp_cut['EVENTO INTERANUAL']
df_cloro_ready['cloro_promedio'] = df_cloro_ready[cloro_estaciones].mean(axis=1)
df_cloro_ready['evento'] = df_cloro_cut['EVENTO INTERANUAL']  # traer original
# Promedio total por estación (temperatura)
temp_mean = df_temp_ready[temp_estaciones].mean()
temp_std = df_temp_ready[temp_estaciones].std()
# Promedio total por estación (clorofila)
cloro_mean = df_cloro_ready[cloro_estaciones].mean()
cloro_std = df_cloro_ready[cloro_estaciones].std()
# Combinar en un solo DataFrame resumen
resumen_estaciones = pd.DataFrame({
'temp_mean': temp_mean,
'temp_std': temp_std,
'cloro_mean': cloro_mean,
'cloro_std': cloro_std
})
print("Resumen de métricas por estación:")
print(resumen_estaciones)
#| echo: false
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
# Seleccionar solo columnas numéricas
X_numeric = resumen_estaciones.select_dtypes(include='number')
# Escalar los datos
scaler = StandardScaler()
X_clustering = scaler.fit_transform(X_numeric)
# Método del codo
inertias = []
K = range(1, 11)
for k in K:
kmeans = KMeans(n_clusters=k, random_state=42)
kmeans.fit(X_clustering)
inertias.append(kmeans.inertia_)
# Gráfico del codo
plt.figure(figsize=(8, 5))
plt.plot(K, inertias, marker='o')
plt.xlabel('Número de clusters (k)')
plt.ylabel('Inercia')
plt.title('Método del codo para encontrar el número óptimo de clusters')
plt.grid(True)
plt.show()
#| echo: false
# PASO 2: Clustering con K-means
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
# Definir número de clusters (ajustable)
n_clusters = 3
# Seleccionar solo las métricas para clustering
X_clustering = resumen_estaciones.values
# Ajustar modelo K-means
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
resumen_estaciones['cluster'] = kmeans.fit_predict(X_clustering)
print("Clusters asignados por estación:")
print(resumen_estaciones[['cluster']])
# Visualización rápida
plt.figure(figsize=(8, 6))
plt.scatter(resumen_estaciones['temp_mean'], resumen_estaciones['cloro_mean'],
c=resumen_estaciones['cluster'], cmap='viridis', s=100)
plt.xlabel('Temperatura media')
plt.ylabel('Clorofila media')
plt.title('Clusters de estaciones')
plt.colorbar(label='Cluster')
plt.show()
#| echo: false
coordenadas = 'data/Coordenadas zona costera occidental GC.csv'
df_coords = pd.read_csv(coordenadas, header=None)
# Eliminar columna con NaNs (columna 1)
df_coords_clean = df_coords.drop(columns=[1])
# Renombrar columnas para claridad
df_coords_clean.columns = ['lon', 'lat']
# Permutar columnas: dejar como lat, lon
df_coords_clean = df_coords_clean[['lat', 'lon']]
df_coords_clean['Estación'] = [f'Est {i+1}°' for i in range(len(df_coords_clean))]
df_coords_clean.columns = df_coords_clean.columns.str.strip()
#| echo: false
# Primero, recuperamos el evento original como columna categórica
df_temp_ready['evento'] = df_temp_cut['EVENTO INTERANUAL']
df_cloro_ready['evento'] = df_cloro_cut['EVENTO INTERANUAL']
# Crear tabla de promedio por estación y evento (para temperatura)
temp_evento_mean = df_temp_ready.groupby('evento')[temp_estaciones].mean().T.reset_index().melt(
id_vars='index', var_name='Evento', value_name='Temp promedio'
).rename(columns={'index': 'Estación'})
# Crear tabla de promedio por estación y evento (para clorofila)
cloro_evento_mean = df_cloro_ready.groupby('evento')[cloro_estaciones].mean().T.reset_index().melt(
id_vars='index', var_name='Evento', value_name='Cloro promedio'
).rename(columns={'index': 'Estación'})
# Unir ambas
respuestas_evento = pd.merge(temp_evento_mean, cloro_evento_mean, on=['Estación', 'Evento'])
# Ordenar por número de estación
respuestas_evento['n_est'] = respuestas_evento['Estación'].str.extract(r'(\d+)').astype(int)
respuestas_evento = respuestas_evento.sort_values('n_est')
# Pivotear a formato ancho por estación
pivot_temp = respuestas_evento.pivot(index='Estación', columns='Evento', values='Temp promedio')
pivot_cloro = respuestas_evento.pivot(index='Estación', columns='Evento', values='Cloro promedio')
# Renombrar columnas para claridad
pivot_temp.columns = [f'Temp_{col}' for col in pivot_temp.columns]
pivot_cloro.columns = [f'Cloro_{col}' for col in pivot_cloro.columns]
# Unir todo
tabla_kmeans = pd.concat([pivot_temp, pivot_cloro], axis=1)
# Ver resultado ordenado
tabla_kmeans = tabla_kmeans.reset_index()
tabla_kmeans['n_est'] = tabla_kmeans['Estación'].str.extract(r'(\d+)').astype(int)
tabla_kmeans = tabla_kmeans.sort_values('n_est').drop(columns='n_est').set_index('Estación')
tabla_kmeans.head(18)
#| echo: false
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
# Escalar los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(tabla_kmeans)
# Método del codo
inertias = []
K = range(1, 11)
for k in K:
kmeans = KMeans(n_clusters=k, random_state=42)
kmeans.fit(X_scaled)
inertias.append(kmeans.inertia_)
# Graficar el codo
plt.figure(figsize=(8, 5))
plt.plot(K, inertias, marker='o')
plt.xlabel('Número de clusters (k)')
plt.ylabel('Inercia')
plt.title('Método del codo para encontrar el número óptimo de clusters')
plt.grid(True)
plt.show()
#| echo: false
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
# Escalar los datos
X = StandardScaler().fit_transform(tabla_kmeans.drop(columns='cluster', errors='ignore'))
# KMeans con 3 clusters
kmeans = KMeans(n_clusters=3, random_state=42)
tabla_kmeans['cluster'] = kmeans.fit_predict(X)
# Crear figura con 3 subplots
fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)
# Títulos de cada evento
eventos = ['Niña', 'Niño', 'Normal']
for i, evento in enumerate(eventos):
axs[i].scatter(tabla_kmeans[f'Temp_{evento}'], tabla_kmeans[f'Cloro_{evento}'],
c=tabla_kmeans['cluster'], cmap='viridis', s=100, edgecolor='k')
axs[i].set_xlabel(f'Temperatura promedio ({evento})')
axs[i].set_title(f'Evento: {evento}')
axs[i].grid(True, linestyle='--', alpha=0.3)
axs[0].set_ylabel('Clorofila promedio')
fig.suptitle('Clusters ENSO por evento (KMeans, k=3)', fontsize=16)
plt.tight_layout()
plt.subplots_adjust(top=0.85)
plt.show()
#| echo: false
tabla_kmeans = tabla_kmeans.reset_index()
tabla_kmeans_geo = pd.merge(tabla_kmeans, df_coords_clean, on='Estación', validate='one_to_one')
#| echo: false
df_temp_long = df_temp_ready.melt(
id_vars=[col for col in df_temp_ready.columns if col not in tabla_kmeans_geo['Estación'].tolist()],
value_vars=tabla_kmeans_geo['Estación'].tolist(),
var_name='Estación',
value_name='TSM'
)
df_cloro_long = df_cloro_ready.melt(
id_vars=[col for col in df_cloro_ready.columns if col not in tabla_kmeans_geo['Estación'].tolist()],
value_vars=tabla_kmeans_geo['Estación'].tolist(),
var_name='Estación',
value_name='Chl_a'
)
# Crear diccionario Estación
cluster_dict = tabla_kmeans_geo.set_index('Estación')['cluster'].to_dict()
# Mapear al DataFrame largo
df_temp_long['cluster'] = df_temp_long['Estación'].map(cluster_dict)
df_cloro_long['cluster'] = df_cloro_long['Estación'].map(cluster_dict)
import statsmodels.api as sm
for i in sorted(df_temp_long['cluster'].unique()):
print(f"\n=== Cluster {i} ===")
cluster_data = df_temp_long[df_temp_long['cluster'] == i]
for est in cluster_data['Estación'].unique():
subset = cluster_data[cluster_data['Estación'] == est]
X = subset[[col for col in subset.columns if col.startswith('AÑO') or
col.startswith('EVENTO INTERANUAL_') or
col.startswith('MES_') or
col.startswith('ESTACIÓN DEL AÑO_')]]
X = sm.add_constant(X)
y = subset['TSM']
modelo = sm.OLS(y, X).fit()
print(f"\n--- Estación: {est} ---")
print(modelo.summary())
